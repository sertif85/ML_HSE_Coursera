{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import pandas\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "#from shad_util import print_answer\n",
    "\n",
    "# 1. Загрузите данные из файла data-logistic.csv. Это двумерная выборка, целевая переменная на которой\n",
    "# принимает значения -1 или 1.\n",
    "\n",
    "df = pandas.read_csv('data-logistic.csv', header=None)\n",
    "y = df[0]\n",
    "X = df.loc[:, 1:]\n",
    "\n",
    "# 2. Убедитесь, что выше выписаны правильные формулы для градиентного спуска. Обратите внимание, что мы используем\n",
    "# полноценный градиентный спуск, а не его стохастический вариант!\n",
    "\n",
    "\n",
    "def fw1(w1, w2, y, X, k, C):\n",
    "    l = len(y)\n",
    "    S = 0\n",
    "    for i in xrange(0, l):\n",
    "        S += y[i] * X[1][i] * (1.0 - 1.0 / (1.0 + math.exp(-y[i] * (w1*X[1][i] + w2*X[2][i]))))\n",
    "\n",
    "    return w1 + (k * (1.0 / l) * S) - k * C * w1\n",
    "\n",
    "\n",
    "def fw2(w1, w2, y, X, k, C):\n",
    "    l = len(y)\n",
    "    S = 0\n",
    "    for i in xrange(0, l):\n",
    "        S += y[i] * X[2][i] * (1.0 - 1.0 / (1.0 + math.exp(-y[i] * (w1*X[1][i] + w2*X[2][i]))))\n",
    "\n",
    "    return w2 + (k * (1.0 / l) * S) - k * C * w2\n",
    "\n",
    "\n",
    "# 3. Реализуйте градиентный спуск для обычной и L2-регуляризованной (с коэффициентом регуляризации 10)\n",
    "# логистической регрессии. Используйте длину шага k=0.1. В качестве начального приближения используйте вектор (0, 0).\n",
    "\n",
    "def grad(y, X, C=0.0, w1=0.0, w2=0.0, k=0.1, err=1e-5):\n",
    "    i = 0\n",
    "    i_max = 10000\n",
    "    w1_new, w2_new = w1, w2\n",
    "\n",
    "    while True:\n",
    "        i += 1\n",
    "        w1_new, w2_new = fw1(w1, w2, y, X, k, C), fw2(w1, w2, y, X, k, C)\n",
    "        e = math.sqrt((w1_new - w1) ** 2 + (w2_new - w2) ** 2)\n",
    "\n",
    "        if i >= i_max or e <= err:\n",
    "            break\n",
    "        else:\n",
    "            w1, w2 = w1_new, w2_new\n",
    "\n",
    "    return [w1_new, w2_new]\n",
    "\n",
    "# 4. Запустите градиентный спуск и доведите до сходимости (евклидово расстояние между векторами весов на соседних\n",
    "# итерациях должно быть не больше 1e-5). Рекомендуется ограничить сверху число итераций десятью тысячами.\n",
    "\n",
    "w1, w2 = grad(y, X)\n",
    "rw1, rw2 = grad(y, X, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.287811620472 0.0919833021593\n",
      "0.0285587545462 0.0247801372497\n"
     ]
    }
   ],
   "source": [
    "print w1, w2\n",
    "print rw1, rw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ee3712695a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_rscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{:0.3f} {:0.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_answer' is not defined"
     ]
    }
   ],
   "source": [
    "# 5. Какое значение принимает AUC-ROC на обучении без регуляризации и при ее использовании?\n",
    "# Эти величины будут ответом на задание. Обратите внимание, что на вход функции roc_auc_score нужно подавать\n",
    "# оценки вероятностей, подсчитанные обученным алгоритмом. Для этого воспользуйтесь сигмоидной функцией:\n",
    "# a(x) = 1 / (1 + exp(-w1 x1 - w2 x2)).\n",
    "\n",
    "\n",
    "def a(X, w1, w2):\n",
    "    return 1.0 / (1.0 + math.exp(-w1 * X[1] - w2 * X[2]))\n",
    "\n",
    "\n",
    "y_score = X.apply(lambda x: a(x, w1, w2), axis=1)\n",
    "y_rscore = X.apply(lambda x: a(x, rw1, rw2), axis=1)\n",
    "\n",
    "auc = roc_auc_score(y, y_score)\n",
    "rauc = roc_auc_score(y, y_rscore)\n",
    "\n",
    "print_answer(1, \"{:0.3f} {:0.3f}\".format(auc, rauc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
