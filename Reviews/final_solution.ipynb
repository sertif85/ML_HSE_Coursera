{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первый этап - градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pandas.read_csv('./data/features.csv', index_col='match_id')\n",
    "test = pandas.read_csv('./data/features_test.csv', index_col='match_id')\n",
    "X_test = test\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['duration','tower_status_radiant', 'tower_status_dire','barracks_status_radiant',\n",
    "            'barracks_status_dire'], axis=1, inplace=True)\n",
    "X_train = train.copy()\n",
    "y_train = train['radiant_win']\n",
    "X_train.drop(['radiant_win'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2. Проверьте выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число\n",
    "заполненных значений. Много ли пропусков в данных? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:\n",
      "97230\n",
      "start_time                     97230\n",
      "lobby_type                     97230\n",
      "r1_hero                        97230\n",
      "r1_level                       97230\n",
      "r1_xp                          97230\n",
      "r1_gold                        97230\n",
      "r1_lh                          97230\n",
      "r1_kills                       97230\n",
      "r1_deaths                      97230\n",
      "r1_items                       97230\n",
      "r2_hero                        97230\n",
      "r2_level                       97230\n",
      "r2_xp                          97230\n",
      "r2_gold                        97230\n",
      "r2_lh                          97230\n",
      "r2_kills                       97230\n",
      "r2_deaths                      97230\n",
      "r2_items                       97230\n",
      "r3_hero                        97230\n",
      "r3_level                       97230\n",
      "r3_xp                          97230\n",
      "r3_gold                        97230\n",
      "r3_lh                          97230\n",
      "r3_kills                       97230\n",
      "r3_deaths                      97230\n",
      "r3_items                       97230\n",
      "r4_hero                        97230\n",
      "r4_level                       97230\n",
      "r4_xp                          97230\n",
      "r4_gold                        97230\n",
      "                               ...  \n",
      "d4_deaths                      97230\n",
      "d4_items                       97230\n",
      "d5_hero                        97230\n",
      "d5_level                       97230\n",
      "d5_xp                          97230\n",
      "d5_gold                        97230\n",
      "d5_lh                          97230\n",
      "d5_kills                       97230\n",
      "d5_deaths                      97230\n",
      "d5_items                       97230\n",
      "first_blood_time               77677\n",
      "first_blood_team               77677\n",
      "first_blood_player1            77677\n",
      "first_blood_player2            53243\n",
      "radiant_bottle_time            81539\n",
      "radiant_courier_time           96538\n",
      "radiant_flying_courier_time    69751\n",
      "radiant_tpscroll_count         97230\n",
      "radiant_boots_count            97230\n",
      "radiant_ward_observer_count    97230\n",
      "radiant_ward_sentry_count      97230\n",
      "radiant_first_ward_time        95394\n",
      "dire_bottle_time               81087\n",
      "dire_courier_time              96554\n",
      "dire_flying_courier_time       71132\n",
      "dire_tpscroll_count            97230\n",
      "dire_boots_count               97230\n",
      "dire_ward_observer_count       97230\n",
      "dire_ward_sentry_count         97230\n",
      "dire_first_ward_time           95404\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print \"size:\"\n",
    "print len(X_train)\n",
    "print X_train.count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование,\n",
    "почему их значения могут быть пропущены.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_player2            43987\n",
      "radiant_flying_courier_time    27479\n",
      "dire_flying_courier_time       26098\n",
      "first_blood_time               19553\n",
      "first_blood_team               19553\n",
      "first_blood_player1            19553\n",
      "dire_bottle_time               16143\n",
      "radiant_bottle_time            15691\n",
      "radiant_first_ward_time         1836\n",
      "dire_first_ward_time            1826\n",
      "radiant_courier_time             692\n",
      "dire_courier_time                676\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train_missing = X_train.isnull().sum().sort_values(ascending=False)\n",
    "print X_train_missing[X_train_missing > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"first blood\" - убийство первого героя противника не так часто происходит в первые 5 минут игры. Предмет \"flying_courier\" cтановится доступным для покупки после 3 минут игры, поэтому это событие с меньшей вероятностью происходит в начале матча."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Замените пропуски на нули с помощью функции fillna(). На самом деле этот способ является предпочтительным\n",
    "для логистической регрессии, поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание.\n",
    "Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — \n",
    "в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева.\n",
    "Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании,\n",
    "но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.Какой столбец содержит целевую переменную? Запишите его название."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'radiant_win'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5.Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на\n",
    "имеющейся матрице \"объекты-признаки\". Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold),\n",
    "не забудьте перемешать при этом выборку (shuffle=True), поскольку данные в таблице отсортированы по времени, \n",
    "и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. Оцените качество \n",
    "градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, попробуйте при этом разное\n",
    "количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). \n",
    "Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях параметра n_estimators,\n",
    "или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Time elapsed: 0:00:18.225971\n",
      "[ 0.66786601  0.66427695  0.65930366  0.6688307   0.66250008]\n",
      "20\n",
      "Time elapsed: 0:00:33.177820\n",
      "[ 0.68077999  0.68397747  0.67945084  0.68162868  0.68659508]\n",
      "30\n",
      "Time elapsed: 0:00:48.548803\n",
      "[ 0.68898572  0.68577347  0.68947223  0.69003901  0.69501449]\n",
      "100\n",
      "Time elapsed: 0:02:40.294670\n",
      "[ 0.69782259  0.71119272  0.70618494  0.71024614  0.7049829 ]\n",
      "150\n",
      "Time elapsed: 0:03:57.885417\n",
      "[ 0.70793896  0.71070899  0.71184107  0.70724822  0.71562737]\n",
      "[0.66455548059959613, 0.68248641380267894, 0.68985698259423223, 0.70608586056516864, 0.71067292098511214]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(y_train)\n",
    "scores = list()\n",
    "n = np.array([10, 20, 30, 100, 150])\n",
    "for i in n:\n",
    "    print i\n",
    "    clf = GradientBoostingClassifier(n_estimators=i, random_state=1)\n",
    "    start_time = datetime.datetime.now()\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=kf, scoring='roc_auc')\n",
    "    print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "    print score\n",
    "    scores.append(np.mean(score))\n",
    "print scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Инструкцию по измерению времени\n",
    "можно найти ниже по тексту. Какое качество при этом получилось? Напомним, что в данном задании мы используем \n",
    "метрику качества AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ~49 секунд, качество, полученное для градиентного бустинга с 30 деревьями составляет 0.69"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что бы вы предложили делать, чтобы\n",
    "ускорить его обучение при увеличении количества деревьев?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Имеет, но в разумных пределах. Чем больше количество деревьев, тем лучше качество мы получаем (например для 150 деревьев - 0.7107), но при бесконечном увеличении этого числа, мы стремимcя к предельному значению качества в ~0.72. Чтобы ускорить процесс можно проводить обучение на меньшем количестве данных или ограничить глубину деревьев с помощью параметра max_depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Второй этап - логистическая регрессия"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "Time elapsed: 0:00:02.274464\n",
      "[ 0.69364753  0.69547581  0.70064405  0.69495789  0.69123879]\n",
      "0.0001\n",
      "Time elapsed: 0:00:03.774591\n",
      "[ 0.70858221  0.71536879  0.71141844  0.71007877  0.71115932]\n",
      "0.001\n",
      "Time elapsed: 0:00:06.501475\n",
      "[ 0.71343284  0.71699011  0.71492851  0.7138472   0.72203752]\n",
      "0.01\n",
      "Time elapsed: 0:00:08.674743\n",
      "[ 0.71436529  0.71737277  0.71098858  0.72239199  0.71718288]\n",
      "0.1\n",
      "Time elapsed: 0:00:09.103536\n",
      "[ 0.71635968  0.72049813  0.71920923  0.71427458  0.71191558]\n",
      "1.0\n",
      "Time elapsed: 0:00:09.116206\n",
      "[ 0.71937401  0.71724919  0.71788862  0.71058863  0.71735001]\n",
      "10.0\n",
      "Time elapsed: 0:00:08.968399\n",
      "[ 0.71717373  0.71137109  0.71874445  0.71426113  0.72007643]\n",
      "100.0\n",
      "Time elapsed: 0:00:09.058584\n",
      "[ 0.70918845  0.71660828  0.71682669  0.72281244  0.71634228]\n",
      "1000.0\n",
      "Time elapsed: 0:00:09.180937\n",
      "[ 0.71737504  0.71272958  0.71487704  0.71528179  0.72120711]\n",
      "10000.0\n",
      "Time elapsed: 0:00:09.217295\n",
      "[ 0.71476217  0.71716021  0.72169752  0.71409446  0.71281683]\n",
      "[0.69519281491042251, 0.71132150586541931, 0.71624723470771479, 0.71646030312492881, 0.71645143929079036, 0.71649008955613447, 0.71632536862318108, 0.71635562655166063, 0.71629411114293651, 0.71610623869429146]\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "n = np.array([0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000])\n",
    "\n",
    "for i in n:\n",
    "    print i\n",
    "    clf = LogisticRegression(penalty='l2', C=i)\n",
    "    start_time = datetime.datetime.now()\n",
    "    score = cross_val_score(clf, scaler.transform(X_train), y_train, cv=kf, scoring='roc_auc')\n",
    "    print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "    print score\n",
    "    scores.append(np.mean(score))\n",
    "print scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Наилучшее качество получается при С=1 и равно 0.71649, что соотносится с качеством для градиентного бустинга при количестве деревьев > 100, и работает за время ~10 секунд."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2.Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "[ 0.69599126  0.6926869   0.69757039  0.68991055  0.69924683]\n",
      "0.0001\n",
      "[ 0.71350157  0.70869569  0.71617826  0.71038897  0.70746881]\n",
      "0.001\n",
      "[ 0.71374805  0.72117997  0.71684766  0.71316796  0.7166652 ]\n",
      "0.01\n",
      "[ 0.72086836  0.71739278  0.71308545  0.71609819  0.71448805]\n",
      "0.1\n",
      "[ 0.71082905  0.71636813  0.71884714  0.71663934  0.71847816]\n",
      "1.0\n",
      "[ 0.72125018  0.715705    0.71792564  0.71169184  0.71587666]\n",
      "10.0\n",
      "[ 0.71460818  0.71478439  0.71606445  0.7184986   0.7182985 ]\n",
      "100.0\n",
      "[ 0.71496183  0.71083225  0.7208133   0.71728106  0.7178246 ]\n",
      "1000.0\n",
      "[ 0.71855478  0.71926795  0.71437935  0.7195682   0.71081177]\n",
      "10000.0\n",
      "[ 0.71489044  0.71657124  0.71388462  0.72325736  0.71321947]\n",
      "[0.6950811857700907, 0.71124665846966484, 0.71632176689898608, 0.71638656743403895, 0.71623236340517105, 0.71648986515610402, 0.71645082446662434, 0.71634260775272107, 0.71651641105003061, 0.71636462831282255]\n"
     ]
    }
   ],
   "source": [
    "X_train.drop(['lobby_type','r1_hero', 'r2_hero','r3_hero','r4_hero', 'r5_hero',\n",
    "        'd1_hero', 'd2_hero','d3_hero','d4_hero', 'd5_hero'], axis=1, inplace=True)\n",
    "\n",
    "y_new_train = train['radiant_win']\n",
    "X_new_train = X_train\n",
    "\n",
    "X_new_train = X_new_train.fillna(0)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(y_new_train)\n",
    "\n",
    "scaler = StandardScaler().fit(X_new_train)\n",
    "n = np.array([0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000])\n",
    "scores = list()\n",
    "for i in n:\n",
    "    print i\n",
    "    clf = LogisticRegression(penalty='l2', C=i)\n",
    "    score = cross_val_score(clf, scaler.transform(X_new_train), y_new_train, cv=kf, scoring='roc_auc')\n",
    "    print score\n",
    "    scores.append(np.mean(score))\n",
    "print scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Качество модели практически не изменилось и составило  0.71651 при C=1000, значит при обучении метод счёл их малозначимыми."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3.На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  67  29 ...,  21  37  84]\n",
      " [ 42  49  67 ...,  79   7  12]\n",
      " [ 33  98  20 ...,  86  29  80]\n",
      " ..., \n",
      " [ 98  11 112 ...,  55  59  31]\n",
      " [100  72  79 ...,  50  28 106]\n",
      " [ 50  19  84 ...,  87 112  97]]\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "hero_table = train[['r1_hero', 'r2_hero','r3_hero','r4_hero', 'r5_hero',\n",
    "        'd1_hero', 'd2_hero','d3_hero','d4_hero', 'd5_hero']].values\n",
    "\n",
    "print hero_table\n",
    "print len(np.unique(hero_table))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Сколько различных идентификаторов героев существует в данной игре?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Всего 108 различных героев используется в предоставленных данных о матчах из возможных 112."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          start_time  r1_level  r1_xp  r1_gold  r1_lh  r1_kills  r1_deaths  \\\n",
      "match_id                                                                     \n",
      "0         1430198770         5   2098     1489     20         0          0   \n",
      "1         1430220345         4   1188     1033      9         0          1   \n",
      "2         1430227081         4   1319     1270     22         0          0   \n",
      "3         1430263531         4   1779     1056     14         0          0   \n",
      "4         1430282290         4   1431     1090      8         1          0   \n",
      "5         1430284186         5   1961     1461     19         0          1   \n",
      "8         1430293701         3    967     1136      7         1          0   \n",
      "9         1430299335         5   2117     1252     16         0          0   \n",
      "11        1430308974         5   1527      906     10         0          1   \n",
      "12        1430316105         5   1651     1060     14         0          1   \n",
      "14        1430325079         5   1988     1804     21         1          0   \n",
      "15        1430330210         3    819      763     12         0          2   \n",
      "17        1430331421         2    611      500      0         0          0   \n",
      "20        1430341277         3    739      585      4         0          0   \n",
      "21        1430342692         2    430      642      1         0          1   \n",
      "22        1430342847         3   1221     1388     18         0          0   \n",
      "23        1430344863         3    786     1088      3         0          0   \n",
      "25        1430352015         4   1435      694      5         0          1   \n",
      "26        1430354106         2    731      500      1         0          1   \n",
      "27        1430355047         4   1697      975      4         0          0   \n",
      "28        1430356392         4   1276     1259      9         1          1   \n",
      "29        1430357535         2    625      789      1         0          0   \n",
      "30        1430358429         5   2081     2187     19         0          0   \n",
      "31        1430363469         0    914      825      4         0          0   \n",
      "32        1430365431         5   1855     2035     35         0          0   \n",
      "34        1430372971         3    802      592      1         0          1   \n",
      "35        1430373522         4   1170     1384      6         2          1   \n",
      "36        1430374551         4   1324     1338     15         0          0   \n",
      "38        1430375522         4   1299     1218     23         0          0   \n",
      "39        1430377785         4   1258     1706     21         1          0   \n",
      "...              ...       ...    ...      ...    ...       ...        ...   \n",
      "114373    1450217420         5   1993     1510     21         0          0   \n",
      "114374    1450220370         5   1699     1575     17         1          1   \n",
      "114375    1450220378         5   2258     1698     23         0          0   \n",
      "114376    1450221758         2    634      500      0         0          1   \n",
      "114379    1450223876         2    548      671      3         0          0   \n",
      "114380    1450224353         3    891     1682     21         1          0   \n",
      "114381    1450225074         3   1682     1611     17         1          0   \n",
      "114382    1450225077         4   1538     1407     19         0          1   \n",
      "114383    1450226303         3   1159     1004      5         1          1   \n",
      "114384    1450227800         2    625      585      2         0          1   \n",
      "114385    1450227829         4   1299     1271     19         0          0   \n",
      "114386    1450228956         3    912     1789     20         2          1   \n",
      "114387    1450229215         4   1383     1603     23         0          0   \n",
      "114388    1450231917         2    763      991      0         1          0   \n",
      "114389    1450233506         3    708     1172      0         2          0   \n",
      "114390    1450242081         5   1930     1535     13         1          0   \n",
      "114391    1450242546         3    549      942      6         1          0   \n",
      "114392    1450244314         5   2387     2085     26         1          0   \n",
      "114394    1450247972         5   2017     1845     32         0          0   \n",
      "114395    1450248756         5   2160     2087     25         1          0   \n",
      "114396    1450249964         5   2038     1420     21         0          1   \n",
      "114397    1450250562         4   1665     1788     30         0          0   \n",
      "114399    1450258083         5   2049     1864     28         0          0   \n",
      "114400    1450263508         5   2097     1910     24         1          1   \n",
      "114401    1450264638         2    730     1110      0         2          0   \n",
      "114402    1450265551         4   1706     1198     17         0          1   \n",
      "114403    1450277704         4   1793     1416     17         0          1   \n",
      "114404    1450291848         4   1399      540      1         0          0   \n",
      "114405    1450292986         3   1135      766      6         0          2   \n",
      "114406    1450313370         3   1053      799      7         0          0   \n",
      "\n",
      "          r1_items  r2_level  r2_xp ...   102  103  104  105  106  107  108  \\\n",
      "match_id                            ...                                       \n",
      "0                7         3    842 ...   0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "1               12         4   1596 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2               12         3   1314 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3                5         2    539 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4                8         2    629 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "5                6         2    441 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "8                8         4   1774 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9                6         3   1378 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "11               7         3    733 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "12              10         3    951 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "14               6         2    537 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "15               9         2    488 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "17               6         2    392 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "20              11         5   2448 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "21               5         2    668 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "22               6         3    731 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "23               9         5   1842 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "25               4         2    551 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "26               8         3    928 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "27               9         2    830 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "28               8         4   1871 ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "29               7         3   1274 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "30               9         4   1433 ...   0.0 -1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "31               4         1   1686 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "32              11         3    741 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "34               7         2    363 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "35               6         3    983 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "36              11         4   1559 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "38               6         4   1591 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "39               6         5   1691 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...            ...       ...    ... ...   ...  ...  ...  ...  ...  ...  ...   \n",
      "114373           4         4   1114 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114374           8         4   1310 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114375           6         5   1912 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114376           6         4   1289 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114379           9         5   2023 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "114380           8         2    280 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114381           9         3    813 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114382           7         4   1390 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "114383           7         5   2093 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114384           7         4   1355 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "114385          10         5   1845 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114386          11         4   1669 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114387           7         2    400 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114388          10         4   1332 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "114389           6         3   1131 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114390           5         4   1288 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114391          11         5   2048 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114392           9         2    483 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114394           6         2    440 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114395           9         4   2182 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "114396           6         4   1737 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114397           9         5   1951 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114399           9         4   1509 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114400          14         3    800 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114401           9         3   1054 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "114402           8         2    616 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114403           5         3    764 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114404           5         4   1448 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114405           6         5   1954 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "114406           7         5   2097 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "\n",
      "          109  110  111  \n",
      "match_id                 \n",
      "0         0.0  0.0  0.0  \n",
      "1         0.0  0.0  0.0  \n",
      "2         0.0  0.0  0.0  \n",
      "3         0.0  0.0  0.0  \n",
      "4         0.0  0.0  0.0  \n",
      "5         0.0  0.0  0.0  \n",
      "8         0.0  0.0  0.0  \n",
      "9         0.0  0.0  0.0  \n",
      "11        0.0  0.0  0.0  \n",
      "12        0.0  0.0  0.0  \n",
      "14        0.0  0.0  0.0  \n",
      "15        0.0  0.0  1.0  \n",
      "17        0.0  0.0  0.0  \n",
      "20        0.0  0.0  0.0  \n",
      "21        0.0  0.0  0.0  \n",
      "22        0.0  0.0  0.0  \n",
      "23        0.0  0.0  0.0  \n",
      "25        0.0  0.0  0.0  \n",
      "26        0.0  0.0  0.0  \n",
      "27        0.0  0.0  0.0  \n",
      "28        0.0  0.0  0.0  \n",
      "29        0.0  0.0  0.0  \n",
      "30        0.0  0.0  1.0  \n",
      "31       -1.0  0.0  0.0  \n",
      "32        0.0  0.0 -1.0  \n",
      "34        1.0  0.0  0.0  \n",
      "35        0.0  0.0  0.0  \n",
      "36        0.0  0.0  0.0  \n",
      "38        0.0  0.0  0.0  \n",
      "39        0.0  0.0  0.0  \n",
      "...       ...  ...  ...  \n",
      "114373    0.0  0.0 -1.0  \n",
      "114374    0.0  0.0  0.0  \n",
      "114375    0.0  0.0 -1.0  \n",
      "114376    0.0  0.0  0.0  \n",
      "114379    0.0  0.0  0.0  \n",
      "114380    0.0  0.0  1.0  \n",
      "114381    0.0  0.0  0.0  \n",
      "114382    0.0  0.0  0.0  \n",
      "114383    0.0  0.0  1.0  \n",
      "114384    0.0  0.0  1.0  \n",
      "114385    0.0  0.0 -1.0  \n",
      "114386    0.0  0.0  0.0  \n",
      "114387    0.0  0.0  0.0  \n",
      "114388   -1.0  0.0  0.0  \n",
      "114389    0.0  0.0  0.0  \n",
      "114390    0.0  0.0  0.0  \n",
      "114391    0.0  0.0  0.0  \n",
      "114392    0.0  0.0  1.0  \n",
      "114394    0.0  0.0  0.0  \n",
      "114395    0.0  0.0  0.0  \n",
      "114396    0.0  0.0  1.0  \n",
      "114397    0.0  0.0  0.0  \n",
      "114399    0.0  0.0  0.0  \n",
      "114400    0.0  0.0  0.0  \n",
      "114401    0.0  0.0 -1.0  \n",
      "114402    0.0  0.0  0.0  \n",
      "114403    1.0  0.0  0.0  \n",
      "114404    0.0  0.0  1.0  \n",
      "114405    0.0  0.0  0.0  \n",
      "114406    0.0  0.0 -1.0  \n",
      "\n",
      "[97230 rows x 203 columns]\n"
     ]
    }
   ],
   "source": [
    "heroes = pandas.read_csv('./data/dictionaries/heroes.csv')\n",
    "N = len(heroes)\n",
    "\n",
    "X_pick = np.zeros((train.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(train.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, train.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, train.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "X_hero = pandas.DataFrame(X_pick, index=X_new_train.index)\n",
    "X_new_train = pandas.concat([X_new_train, X_hero], axis=1)\n",
    "print X_new_train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "[ 0.71843234  0.7156102   0.71385139  0.71088601  0.71551902]\n",
      "0.0001\n",
      "[ 0.74075469  0.74737403  0.7383318   0.74287532  0.74400491]\n",
      "0.001\n",
      "[ 0.74635001  0.75090198  0.7576647   0.75262535  0.7503239 ]\n",
      "0.01\n",
      "[ 0.75375239  0.75227313  0.74873902  0.75181542  0.7531222 ]\n",
      "0.1\n",
      "[ 0.75049137  0.75708429  0.74885475  0.75190454  0.75019258]\n",
      "1.0\n",
      "[ 0.75459088  0.74939511  0.7513796   0.75059092  0.75327184]\n",
      "10.0\n",
      "[ 0.74950101  0.75653499  0.75333634  0.75347756  0.74753082]\n",
      "100.0\n",
      "[ 0.75093868  0.75384154  0.75171322  0.75102651  0.7518409 ]\n",
      "1000.0\n",
      "[ 0.75528206  0.75518696  0.74773371  0.74972502  0.75086866]\n",
      "10000.0\n",
      "[ 0.75085045  0.75337732  0.74734378  0.75772736  0.74959236]\n",
      "[0.71485979178647585, 0.74266815158640154, 0.75157318745114465, 0.75194043068518268, 0.75170550759008958, 0.75184566992436364, 0.75207614279178325, 0.75187216863084216, 0.75175928292962313, 0.75177825314387792]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(y_new_train)\n",
    "scores = list()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "n = np.array([0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000])\n",
    "\n",
    "for i in n:\n",
    "    print i\n",
    "    clf = LogisticRegression(penalty='l2', C=i)\n",
    "    score = cross_val_score(clf, scaler.fit_transform(X_new_train), y_new_train, cv=kf, scoring='roc_auc')\n",
    "    print score\n",
    "    scores.append(np.mean(score))\n",
    "print scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### При добавлении \"мешка слов\" по героям качество модели улучшилось и равно 0.7521 при C = 10. При one-hot-кодировании, линейная модель получает пригодные для предсказания данные в виде вещественных векторов, что упрощает построение разделяющей плоскости."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          start_time  r1_level  r1_xp  r1_gold  r1_lh  r1_kills  r1_deaths  \\\n",
      "match_id                                                                     \n",
      "6         1430287923         4   1103     1089      8         0          1   \n",
      "7         1430293357         2    556      570      1         0          0   \n",
      "10        1430301774         2    751      808      1         0          0   \n",
      "13        1430323933         3    708      903      1         1          1   \n",
      "16        1430331112         4   1259      661      4         0          0   \n",
      "18        1430334264         5   2067     1549     15         0          0   \n",
      "19        1430334995         4   1862     1487     24         0          1   \n",
      "24        1430349466         5   1991     1983     19         2          0   \n",
      "33        1430366484         2    517      500      0         0          1   \n",
      "37        1430375099         3   1060      691      5         0          0   \n",
      "41        1430378434         4   1760     1162     16         0          1   \n",
      "42        1430379583         1    141      619      1         0          0   \n",
      "55        1430393467         2    629      557      0         0          0   \n",
      "60        1430398436         2    572      828      5         0          0   \n",
      "62        1430399788         3   1567     1823     30         0          0   \n",
      "63        1430401076         5   2231     2044     22         0          0   \n",
      "64        1430402407         4   1435     1173     17         0          1   \n",
      "71        1430408743         5   1848     1497     24         0          1   \n",
      "72        1430408794         2    487      499      0         0          0   \n",
      "83        1430421091         2    286      558      0         0          0   \n",
      "85        1430421840         2    892      737      1         0          0   \n",
      "89        1430424264         5   1945     2112     25         2          0   \n",
      "92        1430427279         3   1017     1421     20         0          1   \n",
      "100       1430432885         2    431      984      0         1          0   \n",
      "102       1430435117         3    777      541      1         0          0   \n",
      "108       1430441463         2    454      741      1         0          1   \n",
      "111       1430442629         2    672      537      2         0          0   \n",
      "126       1430455303         2    949      895      2         1          0   \n",
      "130       1430459074         2    464      588      2         0          1   \n",
      "140       1430466608         4   1447     1801     30         0          0   \n",
      "...              ...       ...    ...      ...    ...       ...        ...   \n",
      "114165    1450131598         4   1373     1426     12         1          0   \n",
      "114168    1450132288         3    686      633      0         0          0   \n",
      "114171    1450133142         4   1831     1086     12         0          0   \n",
      "114183    1450135777         2    635      696      4         0          1   \n",
      "114188    1450136846         4   1190     1587     25         0          0   \n",
      "114192    1450137508         2    364      663      4         1          0   \n",
      "114195    1450139129         2    699      663      0         0          0   \n",
      "114202    1450140803         5   2109     1814     21         1          0   \n",
      "114209    1450141777         3   1081      898      3         0          0   \n",
      "114211    1450142038         3   1245     1410     20         0          0   \n",
      "114217    1450143728         5   2246     2287     26         1          0   \n",
      "114232    1450148011         3   1080     1352     15         1          1   \n",
      "114236    1450149079         3    765      775      5         0          1   \n",
      "114238    1450149573         4   1449     1670     22         1          0   \n",
      "114242    1450150528         3   1099     1268     12         0          1   \n",
      "114247    1450152049         3   1210     1439     19         0          0   \n",
      "114285    1450162146         5   1724     1411     22         0          0   \n",
      "114286    1450162461         4   1556      852      9         0          0   \n",
      "114314    1450171844         5   1752     1212     14         0          1   \n",
      "114327    1450179554         3    869      912      3         1          0   \n",
      "114330    1450181136         2    694      638      3         0          1   \n",
      "114337    1450185543         2    763     1066      2         2          1   \n",
      "114348    1450190796         4   1631     1289     19         0          0   \n",
      "114349    1450190965         5   1841     1682     10         1          0   \n",
      "114361    1450203051         5   2176     1980     26         0          0   \n",
      "114369    1450212780         5   2054     1941     27         0          1   \n",
      "114377    1450222875         3    748      605      1         0          0   \n",
      "114378    1450223593         2    575      499      0         0          0   \n",
      "114393    1450244771         4   1844     1176      8         1          2   \n",
      "114398    1450255429         4   1215     1305     13         0          0   \n",
      "\n",
      "          r1_items  r2_level  r2_xp ...   102  103  104  105  106  107  108  \\\n",
      "match_id                            ...                                       \n",
      "6                9         3   1183 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "7                9         4   1194 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "10              13         2    421 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "13              11         2    672 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "16               9         5   1703 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "18               8         4   1258 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "19               5         3    894 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "24              10         4   1498 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "33               9         4   1585 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "37               6         4   1214 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "41               7         2    505 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "42              10         3   1152 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "55               1         4   1530 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "60               4         4   1622 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "62               4         2    474 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "63               7         4   1470 ...   0.0 -1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "64               4         4   1655 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "71               9         3   1032 ...   0.0 -1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "72               8         5   2017 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "83               8         3    681 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "85               7         2    621 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "89              13         3    800 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "92               9         4   1190 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "100              6         4   2273 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "102              8         4   1200 ...   0.0 -1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "108             10         2    582 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "111              7         2    348 ...   0.0  0.0 -1.0  0.0  0.0  0.0  0.0   \n",
      "126              4         4   1532 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "130              8         3    879 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "140              6         5   2161 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...            ...       ...    ... ...   ...  ...  ...  ...  ...  ...  ...   \n",
      "114165          14         5   1923 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114168           8         4   1574 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "114171           7         4   1588 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114183           9         3   1049 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114188          10         2    419 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "114192          11         4   1737 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114195           9         3    940 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114202           9         4   1437 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "114209           8         3   1356 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "114211           9         3   1118 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114217           8         2    392 ...  -1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114232           7         3    870 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114236           9         4   1062 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114238           6         2    372 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114242          10         4   1289 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "114247           7         5   1870 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114285          12         3    887 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114286           8         4   1290 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114314           9         4   1249 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "114327          10         5   2042 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114330           7         4   1554 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "114337           7         3    999 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114348           6         4   1731 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114349          14         3   1014 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "114361           8         3    748 ...   0.0  0.0 -1.0  0.0  0.0  0.0  0.0   \n",
      "114369           8         4   1460 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114377          12         3   1130 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114378           8         3    697 ...   0.0  0.0  0.0 -1.0  0.0  0.0  0.0   \n",
      "114393           8         3   1013 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "114398          10         5   1867 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "          109  110  111  \n",
      "match_id                 \n",
      "6         0.0  0.0  0.0  \n",
      "7         0.0  0.0  0.0  \n",
      "10        0.0  0.0  1.0  \n",
      "13       -1.0  0.0  0.0  \n",
      "16        0.0  0.0  0.0  \n",
      "18        0.0  0.0  0.0  \n",
      "19        0.0  0.0  1.0  \n",
      "24        0.0  0.0  0.0  \n",
      "33        0.0  0.0  0.0  \n",
      "37        0.0  0.0  0.0  \n",
      "41        0.0  0.0  0.0  \n",
      "42        0.0  0.0  0.0  \n",
      "55        0.0  0.0  0.0  \n",
      "60        0.0  0.0  0.0  \n",
      "62        0.0  0.0  0.0  \n",
      "63        0.0  0.0  0.0  \n",
      "64        0.0  0.0  0.0  \n",
      "71        0.0  0.0  0.0  \n",
      "72        1.0  0.0  0.0  \n",
      "83        0.0  0.0  0.0  \n",
      "85        0.0  0.0  0.0  \n",
      "89       -1.0  0.0  0.0  \n",
      "92        0.0  0.0  1.0  \n",
      "100       0.0  0.0  0.0  \n",
      "102       0.0  0.0  0.0  \n",
      "108       0.0  0.0  0.0  \n",
      "111       0.0  0.0  0.0  \n",
      "126       0.0  0.0  0.0  \n",
      "130       0.0  0.0  0.0  \n",
      "140       0.0  0.0  0.0  \n",
      "...       ...  ...  ...  \n",
      "114165    0.0  0.0  0.0  \n",
      "114168    1.0  0.0  0.0  \n",
      "114171    0.0  0.0  0.0  \n",
      "114183    0.0  0.0  0.0  \n",
      "114188    0.0  0.0  0.0  \n",
      "114192    0.0  0.0  0.0  \n",
      "114195    0.0  0.0  0.0  \n",
      "114202    0.0  0.0  0.0  \n",
      "114209    0.0  0.0 -1.0  \n",
      "114211    0.0  0.0  0.0  \n",
      "114217    0.0  0.0  0.0  \n",
      "114232    0.0  0.0  0.0  \n",
      "114236    0.0  0.0  0.0  \n",
      "114238    0.0  0.0  1.0  \n",
      "114242    0.0  0.0  0.0  \n",
      "114247    0.0  0.0  0.0  \n",
      "114285    0.0  0.0  1.0  \n",
      "114286    0.0  0.0  0.0  \n",
      "114314    0.0  0.0 -1.0  \n",
      "114327    0.0  0.0  1.0  \n",
      "114330    0.0  0.0  1.0  \n",
      "114337    0.0  0.0  0.0  \n",
      "114348    0.0  0.0 -1.0  \n",
      "114349    0.0  0.0 -1.0  \n",
      "114361    0.0  0.0 -1.0  \n",
      "114369    0.0  0.0  0.0  \n",
      "114377    0.0  0.0 -1.0  \n",
      "114378    0.0  0.0  0.0  \n",
      "114393    0.0  0.0 -1.0  \n",
      "114398    0.0  0.0  1.0  \n",
      "\n",
      "[17177 rows x 203 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00868998577634\n",
      "0.996487267284\n",
      "          radiant_win\n",
      "match_id             \n",
      "6            0.824995\n",
      "7            0.758552\n",
      "10           0.186991\n",
      "13           0.859399\n",
      "16           0.237548\n",
      "18           0.379512\n",
      "19           0.530337\n",
      "24           0.564540\n",
      "33           0.212069\n",
      "37           0.674474\n",
      "41           0.154922\n",
      "42           0.324287\n",
      "55           0.233739\n",
      "60           0.675504\n",
      "62           0.552531\n",
      "63           0.613138\n",
      "64           0.087765\n",
      "71           0.556069\n",
      "72           0.315564\n",
      "83           0.505678\n",
      "85           0.783118\n",
      "89           0.932450\n",
      "92           0.757473\n",
      "100          0.960659\n",
      "102          0.885839\n",
      "108          0.534843\n",
      "111          0.774635\n",
      "126          0.186858\n",
      "130          0.052473\n",
      "140          0.791328\n",
      "...               ...\n",
      "114165       0.815251\n",
      "114168       0.667554\n",
      "114171       0.462899\n",
      "114183       0.145236\n",
      "114188       0.633485\n",
      "114192       0.843475\n",
      "114195       0.519012\n",
      "114202       0.479319\n",
      "114209       0.385393\n",
      "114211       0.809121\n",
      "114217       0.754378\n",
      "114232       0.386811\n",
      "114236       0.501311\n",
      "114238       0.664925\n",
      "114242       0.582071\n",
      "114247       0.287421\n",
      "114285       0.256152\n",
      "114286       0.409319\n",
      "114314       0.535444\n",
      "114327       0.480234\n",
      "114330       0.411355\n",
      "114337       0.336915\n",
      "114348       0.174812\n",
      "114349       0.596963\n",
      "114361       0.315658\n",
      "114369       0.720421\n",
      "114377       0.632705\n",
      "114378       0.231146\n",
      "114393       0.631958\n",
      "114398       0.425980\n",
      "\n",
      "[17177 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pandas.read_csv('./data/features_test.csv', index_col='match_id')\n",
    "test = test.fillna(0)\n",
    "X_test = test.copy()\n",
    "\n",
    "X_test.drop(['lobby_type','r1_hero', 'r2_hero','r3_hero','r4_hero', 'r5_hero',\n",
    "        'd1_hero', 'd2_hero','d3_hero','d4_hero', 'd5_hero'], axis=1, inplace=True)\n",
    "\n",
    "X_pick = np.zeros((test.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(test.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, test.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, test.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "X_hero = pandas.DataFrame(X_pick, index=X_test.index)\n",
    "X_new_test = pandas.concat([X_test, X_hero], axis=1)\n",
    "print X_new_test\n",
    "\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', C=10)\n",
    "clf.fit(scaler.fit_transform(X_new_train), y_new_train)\n",
    "pred = clf.predict_proba(scaler.fit_transform(X_new_test))[:, 1]\n",
    "\n",
    "print pred.min()\n",
    "print pred.max()\n",
    "kaggle = pandas.DataFrame({'radiant_win': pred}, index=X_test.index)\n",
    "print kaggle\n",
    "kaggle.to_csv(\"dota_win_pred.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Значения 0.0087 и 0.9965 соответственно."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
